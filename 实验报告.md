# 实验报告

## 实验简述

- 环境
  - Pyhton 3.6.2（Anaconda）
  - CUDA 10.0/9.0
  - cuDNN 7.4
  - tensorflow-gpu-1.14.0/1.10.0
  - keras
- 结果
  - 测试准确率：0.9945
- 备注
  - 自行实现 idx 文件读取
    - 绝对路径，如需执行请修改
  - 附有一份英文 README
    - 是作为 GitHub 项目编写时同步更新的详细文档
    - 若觉得本文档有步骤未说明清楚请参见英文文档

## 实验过程

### 读取数据

1.下载 Mnist 数据集

2.分析 idx 文件格式

idx 文件格式如下

- 魔数
  - 前 2 个字节总是 0
  - 第 3 个字节: 数据类型
    - 0x08: unsigned byte
    - 0x09: singned byte
    - 0x0B: short  (2 bytes)
    - 0x0C: int    (4 bytes)
    - 0x0D: float  (4 bytes)
    - 0x0E: double (8 bytes)
  - 第 4 个字节: 维度数量
- 维度 1 大小
- 维度 2 大小
- ......
- 数据

3.通过 struct 模块读取字节流并解析

这里仅贴出 idx3 文件的解析方法，idx1 与之相似

```python
import struct
import numpy as np

def parse_idx3(path):
    # 读取为二进制数据
    bin_data = open(path, 'rb').read()

    # 解析 idx 文件的头部信息
    offset = 0
    # 由于是三维，读前四行
    format_head = '>iiii'
    magic_number, item_num, row_num, col_num = struct.unpack_from(format_head, bin_data, offset)
    # 打印出模数和各维度大小检查
    file_name = path.split('/')[-1].split('.')[0]
    print(('='*15) + file_name + ('='*15))
    print('magic number: %d' % magic_number)
    print('item num: %d, %d row * %d col' % (item_num, row_num, col_num))
    print('=' * (30 + len(file_name)))

    # 解析 idx 文件的数据信息
    item_size = row_num * col_num
    # 每次读取一张图片
    format_data = '>' + str(item_size) + 'B'
    # 把上面读过的头部长度偏移掉
    offset = struct.calcsize(format_head)
    # 返回一个多维数组
    items = np.empty((item_num, row_num, col_num))
    for i in range(item_num):
        items[i] = np.array(struct.unpack_from(format_data, bin_data, offset)).reshape((row_num, col_num))
        offset = offset + struct.calcsize(format_data)
    return items
```

### 数据预处理

1.独热化

对 label 做独热化，以提升其计算距离时的可靠性，优化训练结果

```python
from keras.utils import to_categorical

train_labels = parse_idx1(train_labels_path)
train_labels = to_categorical(train_labels, 10)
```

2.数组预处理

将数组处理成模型能接受并较好地训练的格式

```python
train_images = parse_idx3(train_images_path)
train_images = train_images.reshape(-1, 28, 28, 1)
train_images = train_images.astype('float32')
train_images /= 255
```

### 模型训练

1. 通过 keras 搭建卷积，全连接等层次结构
2. 设定迭代次数和批大小
3. 进行模型训练

```python
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Flatten, Dropout, Dense
from keras.losses import categorical_crossentropy
from keras.optimizers import Adadelta

model = Sequential()
# 卷积层
model.add(Conv2D(32, (5,5), activation='relu', input_shape=[28, 28, 1]))
model.add(Conv2D(64, (5,5), activation='relu'))
# 池化层
model.add(MaxPool2D(pool_size=(2,2)))
# 平铺层
model.add(Flatten())
# 丢弃层
model.add(Dropout(0.5))
# 全连接层
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))
# 设置损失和优化函数
model.compile(loss=categorical_crossentropy, optimizer=Adadelta(), metrics=['accuracy'])

# 批大小
batch_size = 100
# 迭代次数
epochs = 9
# 训练模型
model.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs)
```

### 测评优化

用训练集对模型进行测试，输出准确率

```python
loss, accuracy = model.evaluate(test_images, test_labels, verbose=1)
print('loss: %.4f accuracy: %.4f' %(loss, accuracy))
```

1.参数优化

首次运行，batch_size = 80，epochs = 8，准确率为 0.9926

随后调整 batch_size 为 60 70 75 85 90 100，均会出现 epochs 增加到 9/10 及以上时准确率反而下降的情况

在 batch_size = 80 的条件下，逐步增加 epochs，最后发现在 epochs = 16 处取到最好结果 0.9945

2.模型优化

在建立模型时也尝试做了一些优化，如更改 dropout rate、添加卷积层、更改激活函数，但都未得到准确率的提高...

## 实验感想

1. 自行查阅格式并实现了对 idx 文件的解析，收获很大
2. 虽然主体训练部分使用了 keras 库提供的解决方案，但为了理解每一个方法和参数的含义也下了不少功夫，更好地理解了课堂内容
