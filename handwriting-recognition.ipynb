{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython2",
  "version": 2,
  "kernelspec": {
   "name": "python36264bitpy36conda38ae987df9144d36aeb7041e43accf78",
   "display_name": "Python 3.6.2 64-bit ('py36': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "magic number: 2049\nitem num: 60000\nmagic number: 2051\nitem num: 60000, 28 row * 28 col\n[5. 0. 4. ... 5. 6. 8.]\n[[[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n [[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n [[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n ...\n\n [[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n [[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n [[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]]\n"
    }
   ],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def parse_idx3(path):\n",
    "    # read bin data from file\n",
    "    bin_data = open(path, 'rb').read()\n",
    "\n",
    "    # parse head info\n",
    "    offset = 0\n",
    "    # read first 4 line\n",
    "    format_head = '>iiii'\n",
    "    magic_number, item_num, row_num, col_num = struct.unpack_from(format_head, bin_data, offset)\n",
    "    print('magic number: %d' % magic_number)\n",
    "    print('item num: %d, %d row * %d col' % (item_num, row_num, col_num))\n",
    "\n",
    "    # parse data\n",
    "    item_size = row_num * col_num\n",
    "    # read one item once\n",
    "    format_data = '>' + str(item_size) + 'B'\n",
    "    # set offest to where we have finished reading\n",
    "    offset = struct.calcsize(format_head)\n",
    "    # create an empty array and fill it\n",
    "    items = np.empty((item_num, row_num, col_num))\n",
    "    for i in range(item_num):\n",
    "        items[i] = np.array(struct.unpack_from(format_data, bin_data, offset)).reshape((row_num, col_num))\n",
    "        offset = offset + struct.calcsize(format_data)\n",
    "    return items\n",
    "\n",
    "# same as parse_idx3\n",
    "def parse_idx1(path):\n",
    "    bin_data = open(path, 'rb').read()\n",
    "    offset = 0\n",
    "    format_head = '>ii'\n",
    "    magic_number, item_num = struct.unpack_from(format_head, bin_data, offset)\n",
    "    print('magic number: %d' % magic_number)\n",
    "    print('item num: %d' % item_num)\n",
    "    format_data = '>B'\n",
    "    offset = struct.calcsize(format_head)\n",
    "    items = np.empty(item_num)\n",
    "    for i in range(item_num):\n",
    "        items[i] = struct.unpack_from(format_data, bin_data, offset)[0]\n",
    "        offset = offset + struct.calcsize(format_data)\n",
    "    return items\n",
    "\n",
    "\n",
    "train_labels_path = 'D:/MY/ml-data/handwritting-recognition/train-labels.idx1-ubyte'\n",
    "train_images_path = 'D:/MY/ml-data/handwritting-recognition/train-images.idx3-ubyte'\n",
    "\n",
    "# show first label and image\n",
    "train_labels = parse_idx1(train_labels_path)\n",
    "train_images = parse_idx3(train_images_path)\n",
    "print(train_labels[0])\n",
    "plt.imshow(train_images[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[5 0 4 ... 5 6 8]\n[[[0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  ...\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]]\n\n [[0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  ...\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]]\n\n [[0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  ...\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]]\n\n ...\n\n [[0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  ...\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]]\n\n [[0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  ...\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]]\n\n [[0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  ...\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]]]\n"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# read from file\n",
    "train_labels_path = 'D:/MY/ml-data/handwritting-recognition/train-labels.idx1-ubyte'\n",
    "train_images_path = 'D:/MY/ml-data/handwritting-recognition/train-images.idx3-ubyte'\n",
    "train_labels = parse_idx1(train_labels_path)\n",
    "train_images - parse_idx3(train_images_path)\n",
    "\n",
    "# format array\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "train_images = train_images.reshape(-1, 28, 28, 1)\n",
    "train_images = train_images.astype('float32')\n",
    "train_images /= 255\n",
    "\n",
    "# build model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dropout, Dense\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5,5), activation='relu', input_shape=[28, 28, 1]))\n",
    "model.add(Conv2D(64, (5,5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "             optimizer=Adadelta(),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 8\n",
    "model.fit(train_images, train_labels,\n",
    "         batch_size=batch_size,\n",
    "         epochs=epochs)\n",
    "\n",
    "# load test data and test accuracy\n",
    "train_labels_path = 'D:/MY/ml-data/handwritting-recognition/train-labels.idx1-ubyte'\n",
    "train_images_path = 'D:/MY/ml-data/handwritting-recognition/train-images.idx3-ubyte'\n",
    "test_X, test_y = mnist.load_data()[1]\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X.astype('float32')\n",
    "test_X /= 255\n",
    "test_y = to_categorical(test_y, 10)\n",
    "loss, accuracy = model.evaluate(test_X, test_y, verbose=1)\n",
    "print('loss:%.4f accuracy:%.4f' %(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}